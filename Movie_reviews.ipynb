{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnrIGXrIuTz9LipkgQ7/jn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivanshuPurohit/Practice-models/blob/master/Movie_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoY32fc0qU4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "274c2a1d-a946-433f-a671-bed60d13b126"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(5)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBRLIypjxiZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class training:\n",
        "  \n",
        "  def __init__(self, top_words, max_review_length, embedding_dims):\n",
        "    self.top_words = top_words\n",
        "    self.max_review_length = max_review_length\n",
        "    self.embedding_dims = embedding_dims\n",
        "    \n",
        "  def load_data(self):\n",
        "    \"\"\"\n",
        "    Load the data from the aws instance\n",
        "    \"\"\"\n",
        "    \n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=self.top_words)\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "  \n",
        "  def padding(self, x_train, x_test):\n",
        "    \"\"\"\n",
        "    Clip and pad the reviews to a certain length. Shorter reviews will be padded with 0s\n",
        "    \"\"\"\n",
        "    \n",
        "    x_train = sequence.pad_sequences(x_train, maxlen=self.max_review_length)\n",
        "    x_test = sequence.pad_sequences(x_test, maxlen=self.max_review_length)\n",
        "    return (x_train, x_test)\n",
        "      \n",
        "  def model(self):\n",
        "    \"\"\"\n",
        "    Builds the model\n",
        "    \"\"\"\n",
        "    model= Sequential()\n",
        "    model.add(Embedding(self.top_words, self.embedding_dims, input_length=self.max_review_length))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(1, activation= 'sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "  def train_model(self, model):\n",
        "    \"\"\"\n",
        "    Training the model\n",
        "    \n",
        "    Returns: trained model\n",
        "    \"\"\"\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=1024)\n",
        "    return model\n",
        "   \n",
        "  def test_model(self, model):\n",
        "    \"\"\"\n",
        "    Test the trained model on the test data\n",
        "    \"\"\"\n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TErXPF0PzYDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = training(5000, 500, 100)\n",
        "(x_train, y_train), (x_test, y_test)= training.load_data()\n",
        "(x_train, x_test) = training.padding(x_train, x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hag0I4KUzfr9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "0827696e-9513-44e2-851d-a0404899e540"
      },
      "source": [
        "model = training.model()\n",
        "model = training.train_model(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 42s 2ms/step - loss: 0.6952 - accuracy: 0.5838 - val_loss: 0.6593 - val_accuracy: 0.5884\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 40s 2ms/step - loss: 0.6078 - accuracy: 0.7014 - val_loss: 0.5074 - val_accuracy: 0.7778\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 39s 2ms/step - loss: 0.3867 - accuracy: 0.8351 - val_loss: 0.3597 - val_accuracy: 0.8502\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 38s 2ms/step - loss: 0.2816 - accuracy: 0.8887 - val_loss: 0.3141 - val_accuracy: 0.8699\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 38s 2ms/step - loss: 0.2325 - accuracy: 0.9117 - val_loss: 0.3011 - val_accuracy: 0.8774\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 38s 2ms/step - loss: 0.2018 - accuracy: 0.9276 - val_loss: 0.3170 - val_accuracy: 0.8766\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 40s 2ms/step - loss: 0.1784 - accuracy: 0.9374 - val_loss: 0.3284 - val_accuracy: 0.8716\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 39s 2ms/step - loss: 0.1776 - accuracy: 0.9374 - val_loss: 0.3370 - val_accuracy: 0.8708\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 39s 2ms/step - loss: 0.1621 - accuracy: 0.9439 - val_loss: 0.3415 - val_accuracy: 0.8696\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 39s 2ms/step - loss: 0.1450 - accuracy: 0.9506 - val_loss: 0.3833 - val_accuracy: 0.8648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3XAUvf73aJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}